# This config works for data from eurotat, database migr_asyappctza
# They have to be unpivoted first to look like this:
# citizen,sex,unit,age,asyl_app,geo,year,persons
# AD,F,PER,TOTAL,ASY_APP,AT,2016,0 
# AD,F,PER,TOTAL,ASY_APP,AT,2015,0 
# AD,F,PER,TOTAL,ASY_APP,AT,2014,0 
# AD,F,PER,TOTAL,ASY_APP,AT,2013,0 

# Remarks: 
#  A. Look up the country codes in eurostat
#  B. The document id is needed to prevent duplicates (https://www.elastic.co/blog/logstash-lessons-handling-duplicates)
#  C. As of now, logstash doesn't detect integers or other data types (https://github.com/logstash-plugins/logstash-filter-csv/issues/54)
#  


input { file { path => "/tmp/migr_asyappctza_unpivot_nona.csv" start_position => "beginning" } }

filter { 
  csv { 
    autodetect_column_names => false
    columns => [ "citizen", "sex", "unit", "age", "asyl_app", "geo", "year", "persons" ]
    separator => ","
    add_field => { "document_key" => "%{citizen}_%{sex}_%{age}_%{asyl_app}_%{geo}_%{year}" }
    convert => {
      "persons" => "integer"
      "year" => "date"
    }
  } 
}

#output { file { path => "/tmp/elastic.out" } }

output { 
  elasticsearch {
     hosts => ["your_elasticsearch_host:port"]
     password => "your_password"
     user => "your_user"
     index => "your_index"
     document_id => "%{[document_key]}"
  }
}
